<!-- <!doctype html>
<html>

<head>
    <title>OpenCV Video Examples - Camera</title>
    <link href="app.css" rel="stylesheet">
</head>

<body>
    <h1>OpenCV Camera</h1>
    <div>
        <button id="actionBtn">Start</button>
    </div>
    <video id="video" width="640" height="360"></video>
    <canvas id="canvasOutput"></canvas>
    <script src="test_pipeline.js" type="text/javascript"></script>
    <script>

        Module.onRuntimeInitialized = _ => {
            onReady();
        };

        const video = document.getElementById('video');
        const actionBtn = document.getElementById('actionBtn');
        const width = 640;
        const height = 360;
        const FPS = 30;
        let stream;
        let streaming = false;

        Module['VideoCapture'] = function (videoSource) {
            var video = null;
            if (typeof videoSource === 'string') {
                video = document.getElementById(videoSource);
            } else {
                video = videoSource;
            }
            if (!(video instanceof HTMLVideoElement)) {
                throw new Error('Please input the valid video element or id.');
                return;
            }
            var canvas = document.createElement('canvas');
            canvas.width = video.width;
            canvas.height = video.height;
            var ctx = canvas.getContext('2d');
            this.video = video;
            this.read = function (frame) {
                if (!(frame instanceof Module.Mat)) {
                    throw new Error('Please input the valid cv.Mat instance.');
                    return;
                }
                if (frame.type() !== Module.CV_8UC4) {
                    throw new Error('Bad type of input mat: the type should be cv.CV_8UC4.');
                    return;
                }
                if (frame.cols !== video.width || frame.rows !== video.height) {
                    throw new Error('Bad size of input mat: the size should be same as the video.');
                    return;
                }
                ctx.drawImage(video, 0, 0, video.width, video.height);
                frame.data.set(ctx.getImageData(0, 0, video.width, video.height).data);
            };
        };

        function onReady() {
            var node = new Module.BenchmarkNode;
            let src;
            let dst;
            const cap = new Module.VideoCapture(video);

            actionBtn.addEventListener('click', () => {
                if (streaming) {
                    stop();
                    actionBtn.textContent = 'Start';
                } else {
                    start();
                    actionBtn.textContent = 'Stop';
                }
            });

            function start() {
                navigator.mediaDevices.getUserMedia({ video: true, audio: false })
                        .then(_stream => {
                            stream = _stream;
                            console.log('stream', stream);
                            video.srcObject = stream;
                            video.play();
                            streaming = true;
                            src = new Module.Mat(height, width, Module.CV_8UC4);
                            dst = new Module.Mat(height, width, Module.CV_8UC1);
                            setTimeout(processVideo, 0)
                        })
                        .catch(err => console.log(`An error occurred: ${err}`));
        
    }

            function stop() {
                if (video) {
                    video.pause();
                    video.srcObject = null;
                }
                if (stream) {
                    stream.getVideoTracks()[0].stop();
                }
                streaming = false;
            }

            var cnt = 1;
            function processVideo() {
                if (!streaming) {
                    src.delete();
                    dst.delete();
                    return;
                }
                const begin = Date.now();
                cap.read(src);
                console.log(src);
                node.runFromCamera(src, cnt);
                console.log(cnt);
                cnt = cnt + 1;
                const delay = 1000 / FPS - (Date.now() - begin);
                setTimeout(processVideo, delay);
            }
        }

    </script>
</body>

</html> -->
<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>web RTC</title>

</head>

<body>
  <!-- 这里必须设置autoplay，否则视频画面静止为第一张 -->
  <!-- 必须设置为playsinline，默认全屏播放可能会导致黑屏 -->
  <video id="video" autoplay playsinline></video>
  <script>
    // 习惯性写在函数中，控制变量
   ;(function(){
    //  由于IOS必须在版本11以上才能使用webrtc，并且只有Safari支持，所以做一个小小的判断，限定在
    if(/(iPhone|iPad|iPod|iOS)/i.test(window.navigator.userAgent) && navigator.vender.indexOf("apple") > -1) {
　　　　return;
    }
    /**
     * =============实现在浏览器中打开摄像头，并且将摄像头内容显示在页面中
     * 想要实现这一功能，需要了解webRTC（Web Real-Time Communication）网络实时通话技术，它允许浏览器实现视频、音频、P2P文件分享等功能。
     */
    // 开启视频功能，依赖window的navigator对象，采用getUserMedia方法，有版本差异，所以需要判断区分
    // 需要IE(Edge)15+， Safari 11+， IOS Safari 11.2+, Android 64+, UC 不支持， QQ、百度部分支持

    // 所以首先需要对浏览器支持情况进行判断
    // 先判断浏览器是否支持
    if (navigator.mediaDevices === undefined ||
      navigator.mediaDevices.enumerateDevices === undefined ||
      navigator.mediaDevices.getUserMedia === undefined) {
      // 再判断具体是那个方法不支持，并向用户显示
      if (navigator.mediaDevices === undefined) {
        var fctName = 'navigator.mediaDevices'
      } else if (navigator.mediaDevices.enumerateDevices === undefined) {
        var fctName = 'navigator.mediaDevices.enumerateDevices'
      } else if (navigator.mediaDevices.getUserMedia === undefined) {
        var fctName = 'navigator.mediaDevices.getUserMedia'
      } else {
        console.assert(false)
      }
      alert('WebRTC issue-! ' + fctName + ' not present in your browser')
    }
    const video = document.querySelector('#video')

    // 如果浏览器支持，该方法的更新是向后兼容，新版将所有功能都使用navigator.mediaDevices进行了封装
    navigator.mediaDevices.enumerateDevices().then(function (sourceInfos) {
      // 如果支持新的方法，那么就使用新的方法来获取，当然这是一种比较主流的判断方法
      // 如果是想旧的方法兼容，可以使用下面作为判断条件，除IOS和PC以外，均使用旧的获取方式
      // !(navigator.userAgent.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/) || !/(iPhone|iPad|iPod|iOS|Android)/i.test(navigator.userAgent))
      
      /**
       * 无论是旧的写法还是新的标准，思路都是通过设备信息，获取摄像头的视频流，通过转换变成blob的格式交给video的src
       */
      if (!navigator.mediaDevices.getUserMedia) {
        // 声明一个数组，用于装载设备媒体设备的相关信息，由于回调中sourceInfos对象中携带有所有媒体对象的相关信息
        // 这里对信息进行遍历筛选，只选出摄像头的Id并保存在数组中
        var exArray = [];  
        for (var i = 0; i < sourceInfos.length; ++i) {
          if (sourceInfos[i].kind == 'videoinput') {
            exArray.push(sourceInfos[i].deviceId);
          }
        }
        // 通过navigator的getUserMedia获取摄像头的视频流，并在成功的回调中将视频流交给video
        getMedia();

        function getMedia() {
          if (navigator.getUserMedia) {
            // 该方法可以传递3个参数，分别为获取媒体信息的配置，成功的回调函数和失败的回调函数
            navigator.getUserMedia({
              audio: false, // 表明是否获取音频
              video: {  // 对视频信息进行配置
                optional: [{
                  'sourceId': exArray[1] // 下标为0是前置摄像头，1为后置摄像头，所以PC不能进入该判断，否则画面会保持在第一帧不动
                }]
              },
            }, successFunc, errorFunc); //success是获取成功的回调函数  
          } else {
            alert('Native device media streaming (getUserMedia) not supported in this browser.');
          }
        }
        // 这里是获取媒体信息成功的回调函数
        function successFunc(stream) {
          // 对FireFox进行兼容，这里对返回流数据的处理不同
          if (video.mozSrcObject !== undefined) {
            //Firefox中，video.mozSrcObject最初为null，而不是未定义的，我们可以靠这个来检测Firefox的支持  
            video.mozSrcObject = stream;
          } else {
            // 一般的浏览器需要使用createObjectURL对流数据进行处理，再交给video元素的src
            video.src = window.URL && window.URL.createObjectURL(stream) || stream;
          }
        }
        // 获取媒体信息失败的回调
        function errorFunc(e) {
          alert('Error！' + e);
        }
      } else {  // 当采用最新的标准方式获取视频时
        // 这里对生成视频进行配置
        var userMediaConstraints = {
          audio: false, // 是否获取音频
          video: {
            facingMode: 'environment'  // 环境表示后置摄像头，使用user表示采用前置
          }
        }
        // 这里就采用新的方法来获取视频
        navigator.mediaDevices.getUserMedia(userMediaConstraints).then(function success(stream) {
          video.srcObject = stream;
          video.play();
 
        }).catch(function (error) {
          alert(error.name + error.message)
        });
      }
    }).catch(function(error) {
      alert(error.name + error.message)
    })
   })();
  </script>
</body>

</html>